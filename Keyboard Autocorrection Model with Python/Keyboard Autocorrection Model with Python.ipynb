{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d7ff80-eca8-486c-b811-10d53a82ad98",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24286d63-69c5-4b70-86cd-8e778442486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textdistance\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8776f529-badc-4dba-91df-c376ade9c934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'moby', 'dick', 'or', 'the', 'whale']\n",
      "There are 17647 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "words = []\n",
    "file_path = r\"C:\\Users\\Amruta\\OneDrive\\Desktop\\book.txt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    file_name_data = f.read()\n",
    "    file_name_data=file_name_data.lower()\n",
    "    words = re.findall('\\w+',file_name_data)\n",
    "# This is our vocabulary\n",
    "V = set(words)\n",
    "print(f\"The first ten words in the text are: \\n{words[0:10]}\")\n",
    "print(f\"There are {len(V)} unique words in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae2f0b9-ced2-4e6b-be10-9fd882879bcc",
   "metadata": {},
   "source": [
    "## Build the frequency of those words, which can be easily done by using the counter function in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e17ac49e-ddc6-4992-8875-9165d37b6e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 14703), ('of', 6742), ('and', 6517), ('a', 4799), ('to', 4707), ('in', 4238), ('that', 3081), ('it', 2534), ('his', 2530), ('i', 2120)]\n"
     ]
    }
   ],
   "source": [
    "word_freq_dict = {}\n",
    "word_freq_dict = Counter(words)\n",
    "print(word_freq_dict.most_common()[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23df30f-1cda-40d7-8370-8644471213e5",
   "metadata": {},
   "source": [
    "## Relative Frequency of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39195e-0157-4e9b-ba3f-76f1e8ac54de",
   "metadata": {},
   "source": [
    "Now we want to get the probability of occurrence of each word, this equals the relative frequencies of the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce59beb0-7660-45bc-ad2b-2a0e59a5b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = {}\n",
    "Total = sum(word_freq_dict.values())\n",
    "for k in word_freq_dict.keys():\n",
    "    probs[k] = word_freq_dict[k]/Total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef248764-d0e6-49b7-a29f-9bb72cbc598d",
   "metadata": {},
   "source": [
    "## Finding Similar Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f1641-52da-4021-87a5-66233d8ec7ff",
   "metadata": {},
   "source": [
    "Now we will sort similar words according to the Jaccard distance by calculating the 2 grams Q of the words.\n",
    "Next, we will return the 5 most similar words ordered by similarity and probability:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d478ed2-474e-4385-b7f2-85aabf7bf3ed",
   "metadata": {},
   "source": [
    "## Now, letâ€™s find the similar words by using our autocorrect function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0893483a-3108-4afe-a26e-7216c60af5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Word      Prob  Similarity\n",
      "2571   nevertheless  0.000225    0.666667\n",
      "1105          never  0.000925    0.444444\n",
      "10481     heartless  0.000018    0.416667\n",
      "13557        levers  0.000004    0.400000\n",
      "13600        nestle  0.000004    0.400000\n"
     ]
    }
   ],
   "source": [
    "def my_autocorrect(input_word):\n",
    "    input_word = input_word.lower()\n",
    "    \n",
    "    if input_word in V:\n",
    "        return 'Your word seems to be correct'\n",
    "    else:\n",
    "        similarities = [1 - (textdistance.Jaccard(qval=2).distance(v, input_word)) for v in word_freq_dict.keys()]\n",
    "        df = pd.DataFrame.from_dict(probs, orient='index').reset_index()\n",
    "        df = df.rename(columns={'index': 'Word', 0: 'Prob'})\n",
    "        df['Similarity'] = similarities\n",
    "        output = df.sort_values(['Similarity', 'Prob'], ascending=False).head()\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "result = my_autocorrect('nevertless')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b69ddb6-080f-4b91-9269-0d32ac7c3e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              words     probs  Similarity\n",
      "2571   nevertheless  0.000225    0.666667\n",
      "1105          never  0.000925    0.444444\n",
      "10481     heartless  0.000018    0.416667\n",
      "13557        levers  0.000004    0.400000\n",
      "13600        nestle  0.000004    0.400000\n"
     ]
    }
   ],
   "source": [
    "def my_autocorrect(input_word):\n",
    "    input_word = input_word.lower()\n",
    "    \n",
    "    if input_word in V:\n",
    "        return \"Your word seems to be correct\"\n",
    "    else:\n",
    "        similarities = [1-(textdistance.Jaccard(qval=2).distance(v,input_word)) for v in word_freq_dict.keys()]\n",
    "        df = pd.DataFrame.from_dict(probs,orient= 'index').reset_index()\n",
    "        df = df.rename(columns = {'index': 'words', 0:'probs'})\n",
    "        df['Similarity'] = similarities\n",
    "        output = df.sort_values(['Similarity','probs'], ascending = False).head()\n",
    "        return output\n",
    "        \n",
    "result = my_autocorrect('nevertless')\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
